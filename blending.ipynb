{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from warnings import filterwarnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import optuna\n",
    "\n",
    "sns.set()\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getting and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'kaggle/input'\n",
    "\n",
    "df_train = pd.read_csv(DATA_DIR +'/train.csv')\n",
    "df_test = pd.read_csv(DATA_DIR +'/test.csv')\n",
    "sample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')\n",
    "\n",
    "# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\n",
    "df_train['sample'] = 1 # помечаем где у нас трейн\n",
    "df_test['sample'] = 0  # помечаем где у нас тест\n",
    "df_test['default'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
    "\n",
    "data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['age', 'score_bki', 'decline_app_cnt', 'bki_request_cnt', 'income']\n",
    "cat_cols = ['education', 'first_time', 'sna', 'work_address', 'home_address', 'region_rating']\n",
    "bin_cols = ['sex', 'car', 'car_type', 'good_work', 'foreign_passport']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = data[\"client_id\"]  # сохраним на всякий пожарный\n",
    "data.drop(['client_id','app_date',], axis = 1, inplace=True)\n",
    "\n",
    "# Заполнение пропуски 'education' наиболее частым значением 'SCH'\n",
    "# Можно было бы выделить в отдельную категорию, \"без образования\", пробовал, качество от этого не повышается \n",
    "data[\"education\"].fillna(data.education.mode(), inplace=True)\n",
    "\n",
    "# dummies\n",
    "data = pd.get_dummies(data, columns=['education'], dummy_na=True)\n",
    "\n",
    "# label encoding\n",
    "le = LabelEncoder()\n",
    "\n",
    "for column in bin_cols:\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    \n",
    "columns = ['first_time', 'sna', 'work_address', 'home_address', 'region_rating']\n",
    "\n",
    "for column in columns:\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "\n",
    "# логорифмируем хвостатых\n",
    "data['age'] = np.log(data['age'] + 1)\n",
    "data['decline_app_cnt'] = np.log(data['decline_app_cnt'] + 1)\n",
    "data['income'] = np.log(data['income'] + 1)\n",
    "data['bki_request_cnt'] = np.log(data.bki_request_cnt + 1)\n",
    "\n",
    "# Нормализируем численные\n",
    "for column in num_cols:\n",
    "    data[column] = StandardScaler().fit_transform(np.array(data[column].values).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = (\n",
    "    data.query(\"sample == 1\").drop(columns=[\"sample\", \"default\"]),\n",
    "    data.query(\"sample == 1\")[\"default\"].values,\n",
    ")\n",
    "test = data.query(\"sample == 0\").drop(columns=[\"sample\", \"default\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)\n",
    "X, y = rus.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-14 23:23:03,201]\u001b[0m Using an existing study with name 'LogisticRegression' instead of creating a new one.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"penalty\": trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\"]),\n",
    "        \"solver\": trial.suggest_categorical(\"solver\", [\"liblinear\", \"lbfgs\", \"newton-cg\", \"liblinear\", \"saga\"]),\n",
    "        \"multi_class\": trial.suggest_categorical(\"multi_class\", [\"auto\", \"ovr\"]),\n",
    "        \"C\": trial.suggest_float(\"C\", 1e-10, 1e10, log=True),\n",
    "    }\n",
    "\n",
    "    lr = LogisticRegression(**params)\n",
    "\n",
    "    cv = cross_val_score(lr, X, y, scoring=\"roc_auc\", cv=8, n_jobs=-1)\n",
    "    return np.mean(cv)\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    storage=\"sqlite:///LogisticRegression.db\",\n",
    "    study_name=\"LogisticRegression\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(objective, timeout=600, n_trials=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.07213528501783559,\n",
       " 'multi_class': 'ovr',\n",
       " 'penalty': 'l2',\n",
       " 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-14 23:23:03,576]\u001b[0m Using an existing study with name 'LGBMClassifier' instead of creating a new one.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
    "        \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    gbm = LGBMClassifier(**param, silent=True)\n",
    "    cv_roc_auc = cross_val_score(gbm, X, y, cv=8, scoring=\"roc_auc\", n_jobs=-1)\n",
    "\n",
    "    return np.mean(cv_roc_auc)\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    storage=\"sqlite:///LGBMClassifier.db\",\n",
    "    study_name=\"LGBMClassifier\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(objective, timeout=600, n_trials=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.6641812860565748,\n",
       " 'bagging_freq': 3,\n",
       " 'feature_fraction': 0.4257771924417812,\n",
       " 'lambda_l1': 0.41391873003799096,\n",
       " 'lambda_l2': 0.009238732952784297,\n",
       " 'min_child_samples': 76,\n",
       " 'num_leaves': 9}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-14 23:23:04,004]\u001b[0m Using an existing study with name 'CatBoostClassifier' instead of creating a new one.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    param = {\n",
    "        \"objective\": trial.suggest_categorical(\"objective\", [\"Logloss\", \"CrossEntropy\"]),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 12),\n",
    "        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]),\n",
    "        \"used_ram_limit\": \"6gb\",\n",
    "    }\n",
    "\n",
    "    if param[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
    "    elif param[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "        param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n",
    "\n",
    "    gbm = CatBoostClassifier(**param, silent=True)\n",
    "    cv_roc_auc = cross_val_score(gbm, X, y, cv=8, scoring=\"roc_auc\", n_jobs=-1)\n",
    "\n",
    "    return np.mean(cv_roc_auc)\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    storage=\"sqlite:///CatBoostClassifier.db\",\n",
    "    study_name=\"CatBoostClassifier\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(objective, timeout=600, n_trials=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'Ordered',\n",
       " 'bootstrap_type': 'Bernoulli',\n",
       " 'colsample_bylevel': 0.07494834574844549,\n",
       " 'depth': 12,\n",
       " 'objective': 'CrossEntropy',\n",
       " 'subsample': 0.9809549562352028}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_models = [\n",
    "    LinearRegression(),\n",
    "    LogisticRegression(\n",
    "        **{\n",
    "            \"C\": 0.07213528501783559,\n",
    "            \"multi_class\": \"ovr\",\n",
    "            \"penalty\": \"l2\",\n",
    "            \"solver\": \"liblinear\",\n",
    "        },\n",
    "        random_state=42\n",
    "    ),\n",
    "    RandomForestClassifier(n_estimators=256, random_state=42),\n",
    "    LGBMClassifier(\n",
    "        **{\n",
    "            \"bagging_fraction\": 0.6641812860565748,\n",
    "            \"bagging_freq\": 3,\n",
    "            \"feature_fraction\": 0.4257771924417812,\n",
    "            \"lambda_l1\": 0.41391873003799096,\n",
    "            \"lambda_l2\": 0.009238732952784297,\n",
    "            \"min_child_samples\": 76,\n",
    "            \"num_leaves\": 9,\n",
    "        },\n",
    "        random_state=42,\n",
    "        silent=True\n",
    "    ),\n",
    "    CatBoostClassifier(\n",
    "        # **{\n",
    "        #     \"boosting_type\": \"Ordered\",\n",
    "        #     \"bootstrap_type\": \"Bernoulli\",\n",
    "        #     \"colsample_bylevel\": 0.07494834574844549,\n",
    "        #     \"depth\": 12,\n",
    "        #     \"objective\": \"CrossEntropy\",\n",
    "        #     \"subsample\": 0.9809549562352028,\n",
    "        # },\n",
    "        random_state=42,\n",
    "        silent=True\n",
    "    ),\n",
    "]\n",
    "simple_models_names = [\"linear\", \"logistic\", \"rf\", \"lgbm\", \"catboost\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.2, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting linear done\n",
      "Fitting logistic done\n",
      "Fitting rf done\n",
      "Fitting lgbm [LightGBM] [Warning] bagging_fraction is set=0.6641812860565748, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6641812860565748\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.41391873003799096, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.41391873003799096\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4257771924417812, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4257771924417812\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.009238732952784297, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.009238732952784297\n",
      "done\n",
      "Fitting catboost done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear</th>\n",
       "      <th>logistic</th>\n",
       "      <th>rf</th>\n",
       "      <th>lgbm</th>\n",
       "      <th>catboost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.391481</td>\n",
       "      <td>0.376763</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.382711</td>\n",
       "      <td>0.335971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.654895</td>\n",
       "      <td>0.672962</td>\n",
       "      <td>0.707031</td>\n",
       "      <td>0.665023</td>\n",
       "      <td>0.654139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.628189</td>\n",
       "      <td>0.641612</td>\n",
       "      <td>0.667969</td>\n",
       "      <td>0.716308</td>\n",
       "      <td>0.736752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     linear  logistic        rf      lgbm  catboost\n",
       "0  0.391481  0.376763  0.328125  0.382711  0.335971\n",
       "1  0.654895  0.672962  0.707031  0.665023  0.654139\n",
       "2  0.628189  0.641612  0.667969  0.716308  0.736752"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df = pd.DataFrame()\n",
    "for name, model in zip(simple_models_names, simple_models):\n",
    "    print(\"Fitting\", name, end = \" \")\n",
    "    if name != \"linear\":\n",
    "        model.fit(X_train, y_train)\n",
    "        meta_df[name] = model.predict_proba(X_val)[:,1]\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        meta_df[name] = model.predict(X_val)\n",
    "    print(\"done\")\n",
    "\n",
    "meta_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting using linear done\n",
      "Predicting using logistic done\n",
      "Predicting using rf done\n",
      "Predicting using lgbm done\n",
      "Predicting using catboost done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear</th>\n",
       "      <th>logistic</th>\n",
       "      <th>rf</th>\n",
       "      <th>lgbm</th>\n",
       "      <th>catboost</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.257588</td>\n",
       "      <td>0.245833</td>\n",
       "      <td>0.207031</td>\n",
       "      <td>0.209238</td>\n",
       "      <td>0.178658</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.733078</td>\n",
       "      <td>0.754758</td>\n",
       "      <td>0.820312</td>\n",
       "      <td>0.692517</td>\n",
       "      <td>0.927645</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.336925</td>\n",
       "      <td>0.320274</td>\n",
       "      <td>0.367188</td>\n",
       "      <td>0.358034</td>\n",
       "      <td>0.443330</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     linear  logistic        rf      lgbm  catboost  preds\n",
       "0  0.257588  0.245833  0.207031  0.209238  0.178658      0\n",
       "1  0.733078  0.754758  0.820312  0.692517  0.927645      1\n",
       "2  0.336925  0.320274  0.367188  0.358034  0.443330      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_model = CatBoostClassifier(random_state=42, silent=True)\n",
    "meta_model.fit(meta_df, y_val)\n",
    "\n",
    "test_meta_df = pd.DataFrame()\n",
    "for name, model in zip(simple_models_names, simple_models):\n",
    "    print(\"Predicting using\", name, end = \" \")\n",
    "    if name != \"linear\":\n",
    "        test_meta_df[name] = model.predict_proba(test)[:,1]\n",
    "    else:\n",
    "        test_meta_df[name] = model.predict(test)\n",
    "    print(\"done\")\n",
    "\n",
    "test_meta_df[\"preds\"] = meta_model.predict(test_meta_df)\n",
    "test_meta_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_id  default\n",
       "0      74835        0\n",
       "1      17527        0\n",
       "2      75683        0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission[\"default\"] = test_meta_df[\"preds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kaggle: 0.34142"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "995ee929d4551839aa49ca7a1183d413d9a8d51b673f4509586a2b7bfb4ef704"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
